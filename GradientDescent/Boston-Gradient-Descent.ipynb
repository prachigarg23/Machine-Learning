{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent on boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, datasets\n",
    "from sklearn import cross_validation as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_cost(X, Y, coef):\n",
    "    cost = 0\n",
    "    N = len(Y)\n",
    "    cost = np.sum((Y - (X.dot(coef))) **2)\n",
    "    cost = cost/N\n",
    "    return cost\n",
    "\n",
    "\n",
    "def gd_step(X, Y, l_rate, coef):\n",
    "    Y = np.reshape(Y, (len(Y), 1))\n",
    "    N = len(Y)\n",
    "    hox = X.dot(coef)\n",
    "    loss = hox - Y\n",
    "    c = X.T\n",
    "    grad = c.dot(loss)\n",
    "    grad = grad*(2/N)\n",
    "    coef = coef - l_rate*(grad)\n",
    "    return coef\n",
    "\n",
    "def gd_runner(X, Y, learning_rate=0.02, num_iter=1):\n",
    "    arb, count = X.shape\n",
    "    coef = np.random.rand(count,1)\n",
    "    print(\"cost before gd = \" + str(gd_cost(X, Y, coef)))\n",
    "    for i in range(num_iter):\n",
    "        coef = gd_step(X, Y, learning_rate, coef)\n",
    "    print(\"cost = \" + str(gd_cost(X, Y, coef)))\n",
    "    return coef\n",
    "\n",
    "def predict(X_test, coef):\n",
    "    Y_pred = X_test.dot(coef)\n",
    "    print(Y_pred.shape)\n",
    "    return Y_pred    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
      "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "\n",
      "       11    12  \n",
      "0  396.90  4.98  \n",
      "1  396.90  9.14  \n",
      "2  392.83  4.03  \n",
      "3  394.63  2.94  \n",
      "4  396.90  5.33  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data)\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(df, boston.target, test_size=0.2)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost before gd = 236025.53740211346\n",
      "cost = 54237.89191547447\n",
      "(102, 1)\n",
      "(102, 1)\n",
      "[26.7108202]\n",
      "[20.87598728]\n",
      "[7.00654242]\n",
      "[29.78720258]\n",
      "[9.00158037]\n",
      "[20.55327204]\n",
      "[4.18101906]\n",
      "[13.50961093]\n",
      "[14.41582192]\n",
      "[20.12566946]\n"
     ]
    }
   ],
   "source": [
    "num_iter = 30\n",
    "rate = 0.05\n",
    "arr = np.full((len(Y_train), 1), 1)\n",
    "X = np.append(arr, X_train, axis=1)\n",
    "arr = np.full((len(X_test), 1), 1)\n",
    "X_test1 = np.append(arr, X_test, axis=1)\n",
    "\n",
    "\n",
    "coef = gd_runner(X, Y_train, rate, num_iter)\n",
    "Y_pred = predict(X_test1, coef)\n",
    "print(Y_pred.shape)\n",
    "for i in Y_pred[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.25804223204009\n",
      "22.68853552705916\n",
      "7.618069657452875\n",
      "29.98570163195754\n",
      "11.244948871327583\n",
      "21.09949003133345\n",
      "5.636109299785527\n",
      "14.050016774097635\n",
      "14.57836132983837\n",
      "21.482979330109227\n",
      "score = 0.7057788837752907\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDRegressor(alpha=0.05, max_iter=30)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred2 = clf.predict(X_test)\n",
    "\n",
    "for i in Y_pred2[:10]:\n",
    "    print(i)\n",
    "    \n",
    "print(\"score = \" + str(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.81063568,  0.39460882, -0.1030158 ,  0.62703354, -1.4554976 ,\n",
       "        2.6844791 ,  0.05508609, -2.03899991,  1.28295367, -0.97698641,\n",
       "       -2.09734866,  0.72435714, -3.455553  ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't perform feature scaling on this dataset, we get nan in all X_test predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding higher degree terms to the hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "df2 = pd.DataFrame(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(X_old):\n",
    "    n,m = X_old.shape\n",
    "    X_new = np.array(X_old)\n",
    "    for i in range(m):\n",
    "        arr = X_old[:,i]**2\n",
    "        arr = np.reshape(arr,(n,1))\n",
    "        X_new = np.append(X_new, arr, axis=1)\n",
    "    print(X_new.shape)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 26)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(df2)\n",
    "X_new = add_features(data)\n",
    "scaler = preprocessing.StandardScaler().fit(X_new)\n",
    "X_new = scaler.transform(X_new)\n",
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(X_new, boston.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.540542525452278\n",
      "22.275257312300727\n",
      "25.552631753003123\n",
      "27.50013677548943\n",
      "20.12066673436285\n",
      "10.226145639177735\n",
      "22.24414674401155\n",
      "23.840270690830305\n",
      "17.80596555606552\n",
      "20.506087858008478\n",
      "score = 0.8403898369585207\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDRegressor(alpha=0.05, max_iter=30)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred2 = clf.predict(X_test)\n",
    "\n",
    "for i in Y_pred2[:10]:\n",
    "    print(i)\n",
    "    \n",
    "print(\"score = \" + str(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost before gd = 237306.1313267127\n",
      "cost = 57597.14025726429\n",
      "(102, 1)\n",
      "(102, 1)\n",
      "[23.54356026]\n",
      "[22.1351292]\n",
      "[25.10988443]\n",
      "[27.29360181]\n",
      "[20.37988166]\n",
      "[9.26519124]\n",
      "[21.37971198]\n",
      "[23.84158654]\n",
      "[18.12297202]\n",
      "[20.33091598]\n"
     ]
    }
   ],
   "source": [
    "num_iter = 50\n",
    "rate = 0.05\n",
    "arr = np.full((len(Y_train), 1), 1)\n",
    "X = np.append(arr, X_train, axis=1)\n",
    "arr = np.full((len(X_test), 1), 1)\n",
    "X_test1 = np.append(arr, X_test, axis=1)\n",
    "\n",
    "\n",
    "coef = gd_runner(X, Y_train, rate, num_iter)\n",
    "Y_pred = predict(X_test1, coef)\n",
    "print(Y_pred.shape)\n",
    "for i in Y_pred[:10]:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
