{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K Nearest Neighbours for classification on Breast Cancer dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9    ...        20     21      22      23      24      25      26  \\\n",
       "0  0.07871   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.05667   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.05999   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.09744   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.05883   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       27      28       29  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data)\n",
    "print(cancer.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cancer.target_names)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dataset contains of 30 continuous value features\n",
    "<br>\n",
    "> There are 2 target class - malignant(cancer positive) and benign(cancer negative)\n",
    "<br>\n",
    "> Let us first find accuracy using logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(cancer.data, cancer.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "        0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, Y_test))\n",
    "Y_pred-Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the sklearn KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf2 = KNeighborsClassifier(weights='uniform', algorithm='auto', p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181286549707602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  1,  0,\n",
       "        0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "        0,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,\n",
       "        0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "        0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, Y_train)\n",
    "Y_pred = clf2.predict(X_test)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(clf2.score(X_test, Y_test))\n",
    "Y_pred - Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE WILL PLOT THE NUMBER OF NEIGHBOURS AGAINST THE SCORE OBTAINED EACH TIME TO ESTIMATE THE VALUE OF K WITH HIGHEST ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [0]\n",
    "scores = [0]\n",
    "for k in range(1,50,2):\n",
    "    x_axis.append(k)\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scores.append(clf.score(X_test, Y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c441a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis, scores)\n",
    "plt.show()\n",
    "optimal_k = x_axis[scores.index(max(scores))]\n",
    "print(optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "clf3 = KNeighborsClassifier(n_neighbors=optimal_k, weights='uniform', algorithm='auto', p=2)\n",
    "clf2.fit(X_train, Y_train)\n",
    "Y_pred = clf2.predict(X_test)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(clf2.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# x_test= single data point to be tested\n",
    "\n",
    "k = optimal_k\n",
    "def getkey(item):\n",
    "    return item[0]\n",
    "\n",
    "def predict(x_test, x_train, y_train):\n",
    "    dist_arr = [[0 for i in range(2)] for i in range(len(y_train))]\n",
    "    get_k = [[0 for i in range(2)] for i in range(k)]\n",
    "    get_result = [0 for i in range(k)]\n",
    "    for i in range(len(x_train)):\n",
    "        sum = 0\n",
    "        for f in range(len(x_train[i])):\n",
    "            sum += (x_test[f]-x_train[i][f])**2\n",
    "        dist_arr[i][0]=np.sqrt(sum)\n",
    "        dist_arr[i][1]=i\n",
    "    dist_arr = sorted( dist_arr, key = getkey)\n",
    "    get_k = dist_arr[:k]\n",
    "    # we got top k distances and the points from which they were measured in get_k \n",
    "    count = [0 for i in range(2)]\n",
    "    # the next 2 lines count how many of the k neighbours belong to class 0 and class 1 , it stored the count in count[0], count[1]\n",
    "    for i in range(k):\n",
    "        count[y_train[get_k[i][1]]] += 1\n",
    "    # return the class of the majority neighbors\n",
    "    return count.index(np.max(count))\n",
    "\n",
    "x_test = X_test[0]\n",
    "print(predict(x_test, X_train, Y_train))\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1 -1  0  0  0  0\n",
      " -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0\n",
      "  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0  0  0  0  0  0  1  0  0\n",
      "  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# predicting on entire test dataset using predict function written above\n",
    "Y_predicted = []\n",
    "for i in range(len(X_test)):\n",
    "    Y_predicted.append(predict(X_test[i], X_train, Y_train)) \n",
    "print(Y_predicted - Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "def score1(Y_predicted, Y_test):\n",
    "    error = sum(abs(Y_predicted-Y_test))/len(Y_test)\n",
    "    accuracy = 1-error\n",
    "    print(accuracy)\n",
    "score1(Y_predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
